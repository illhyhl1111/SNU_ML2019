{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab2_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/illhyhl1111/SNU_ML2019/blob/master/Lab2_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sbkFbNUAKyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import Compose,ToTensor\n",
        "\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-mCz91mryvd",
        "colab_type": "text"
      },
      "source": [
        "#### Connect to local google drive & settings for export/import models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_1Cr9tsrydl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "!mkdir ./gdrive/'My Drive'/MNIST_models/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2nLnUERGaL_",
        "colab_type": "text"
      },
      "source": [
        "#### DNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV9KcFU1FKsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MNISTDNN(nn.Module):\n",
        "    def __init__(self,IMG_SIZE=28):\n",
        "        super(MNISTDNN,self).__init__()\n",
        "        self.fc1 = nn.Linear(IMG_SIZE*IMG_SIZE,32)\n",
        "        self.BN1 = torch.nn.BatchNorm1d(32)\n",
        "        self.fc2 = nn.Linear(32,10)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.BN1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = torch.softmax(x,dim=-1)\n",
        "        return x    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNCKxXJwGdN4",
        "colab_type": "text"
      },
      "source": [
        "#### CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvofB0pnGfHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MNISTCNN(nn.Module):\n",
        "    def __init__(self,IMG_SIZE=28):\n",
        "        super(MNISTCNN,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1,8,5,stride=2)\n",
        "        self.BN1 = torch.nn.BatchNorm2d(8)\n",
        "        self.conv2 = nn.Conv2d(8,8,5,stride=2)\n",
        "        self.BN2 = torch.nn.BatchNorm2d(8)\n",
        "        self.conv3 = nn.Conv2d(8,8,3,stride=1)\n",
        "        self.fc = nn.Linear(8*2*2,10)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.BN1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.BN2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = x.view(-1,8*2*2)\n",
        "        x = self.fc(x)\n",
        "        x = torch.softmax(x,dim=-1)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zyvh6IKYZcdi",
        "colab_type": "text"
      },
      "source": [
        "#### Util function for calculating accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YSzoolPQqIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_acc(argmax,y):\n",
        "    count = 0\n",
        "    for i in range(len(argmax)):\n",
        "        if argmax[i]==y[i]:\n",
        "            count+=1\n",
        "    return count / len(argmax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7KNrp6hGXWI",
        "colab_type": "text"
      },
      "source": [
        "#### hyperparameters & datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vny-hSnYGOx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE = 28\n",
        "BATCH_SIZE = 256\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHES = 30\n",
        "IS_DNN = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpnCYlVHBuSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms = Compose([\n",
        "    ToTensor(),\n",
        "])\n",
        "\n",
        "trainset = MNIST('/content/gdrive/My Drive/MNIST_models/',train=True,transform=transforms,download=True)\n",
        "testset = MNIST('/content/gdrive/My Drive/MNIST_models/',train=False,transform=transforms,download=True)\n",
        "\n",
        "args = {\n",
        "    'num_workers' : 1,\n",
        "    'batch_size' : BATCH_SIZE,\n",
        "    'shuffle' : True,\n",
        "}\n",
        "\n",
        "train_loader = DataLoader(trainset,**args)\n",
        "test_loader = DataLoader(testset,**args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw9IBUpYZPqb",
        "colab_type": "text"
      },
      "source": [
        "####Training part(DNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPSsZM0uGs2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if IS_DNN:\n",
        "    model = MNISTDNN(IMG_SIZE).cuda()\n",
        "\n",
        "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    num_params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "    print(\"number of parameters : {}\".format(num_params))\n",
        "    \n",
        "    optimizer = Adam(model.parameters(),lr=LEARNING_RATE)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(NUM_EPOCHES):\n",
        "        tot_loss = 0.0\n",
        "        \n",
        "        for x,y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            x = x.cuda().view(-1,IMG_SIZE*IMG_SIZE)\n",
        "            y_ = model(x)\n",
        "            loss = loss_fn(y_, y.cuda())\n",
        "            loss.backward()\n",
        "            tot_loss+=loss.item()\n",
        "            optimizer.step()\n",
        "            \n",
        "        print(\"Epoch {}, Loss(train) : {}\".format(epoch+1,tot_loss))\n",
        "        if epoch % 2 == 1:\n",
        "            x,y = next(iter(test_loader))\n",
        "            x = x.cuda().view(-1,IMG_SIZE*IMG_SIZE)\n",
        "            y_ = model(x)\n",
        "            _, argmax = torch.max(y_,dim=-1)\n",
        "            test_acc = compute_acc(argmax,y.numpy())\n",
        "            \n",
        "            print(\"Acc(val) : {}\".format(test_acc))\n",
        "\n",
        "    torch.save(model.state_dict(), \"/content/gdrive/My Drive/MNIST_models/DNN.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyC_PAFPMPLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_test = MNISTDNN(IMG_SIZE).cuda()\n",
        "model_test.load_state_dict(torch.load(\"/content/gdrive/My Drive/MNIST_models/DNN.pt\"))\n",
        "model_test.eval()\n",
        "x,y = next(iter(test_loader))\n",
        "x = x.cuda().view(-1,IMG_SIZE*IMG_SIZE)\n",
        "y_ = model_test(x)\n",
        "_, argmax = torch.max(y_,dim=-1)\n",
        "test_acc = compute_acc(argmax,y.numpy())\n",
        "\n",
        "print(\"Acc(test) : {}\".format(test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZlMbw_tZLT-",
        "colab_type": "text"
      },
      "source": [
        "#### Training part(CNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_hp82IXWJ4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not IS_DNN:\n",
        "    model = MNISTCNN(IMG_SIZE).cuda()\n",
        "\n",
        "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    num_params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "    print(\"number of parameters : {}\".format(num_params))\n",
        "    \n",
        "    optimizer = Adam(model.parameters(),lr=LEARNING_RATE)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(NUM_EPOCHES):\n",
        "        tot_loss = 0.0\n",
        "        \n",
        "        for x,y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            x = x.cuda()\n",
        "            y_ = model(x)\n",
        "            loss = loss_fn(y_, y.cuda())\n",
        "            loss.backward()\n",
        "            tot_loss+=loss.item()\n",
        "            optimizer.step()\n",
        "            \n",
        "        print(\"Epoch {}, Loss(train) : {}\".format(epoch+1,tot_loss))\n",
        "        if epoch % 2 == 1:\n",
        "            model.eval()\n",
        "            \n",
        "            x,y = next(iter(test_loader))\n",
        "            x = x.cuda()\n",
        "            y_ = model(x)\n",
        "            _, argmax = torch.max(y_,dim=-1)\n",
        "            test_acc = compute_acc(argmax,y.numpy())\n",
        "            \n",
        "            print(\"Acc(test) : {}\".format(test_acc))\n",
        "            \n",
        "            model.train()\n",
        "\n",
        "    torch.save(model.state_dict(), \"/content/gdrive/My Drive/MNIST_models/CNN.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xhN_wmbMR41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_test = MNISTCNN(IMG_SIZE).cuda()\n",
        "model_test.load_state_dict(torch.load(\"/content/gdrive/My Drive/MNIST_models/CNN.pt\"))\n",
        "model_test.eval()\n",
        "x,y = next(iter(test_loader))\n",
        "x = x.cuda()\n",
        "y_ = model_test(x)\n",
        "_, argmax = torch.max(y_,dim=-1)\n",
        "test_acc = compute_acc(argmax,y.numpy())\n",
        "\n",
        "print(\"Acc(test) : {}\".format(test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}